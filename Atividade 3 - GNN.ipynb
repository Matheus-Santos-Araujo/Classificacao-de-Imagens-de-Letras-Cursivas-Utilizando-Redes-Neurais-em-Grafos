{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric import utils\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from deepsnap.dataset import GraphDataset\n",
    "from deepsnap.batch import Batch\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_parse():\n",
    "    parametros = argparse.ArgumentParser(description='Cassificação de letras do alfabeto.')\n",
    "\n",
    "    parametros.set_defaults(\n",
    "            epocas = 500,\n",
    "            modelo = 'GIN', # GIN, GCN, GAT\n",
    "            batch_size = 16,\n",
    "            hidden_dim = 30,\n",
    "            num_layers = 2,\n",
    "            weight_decay = 3e-4,\n",
    "            dropout = 0.1,\n",
    "            learningrate = 0.001\n",
    "    )\n",
    "    return parametros.parse_known_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Carrega os parâmetros\n",
    "args, unknown = arg_parse()\n",
    "\n",
    "# Carrega o dataset (low, med ou high)\n",
    "pyg_dataset = TUDataset('./Letter-low', 'Letter-low', use_node_attr = True)\n",
    "#pyg_dataset = TUDataset('./Letter-med', 'Letter-med', use_node_attr = True)\n",
    "#pyg_dataset = TUDataset('./Letter-high', 'Letter-high', use_node_attr = True)\n",
    "\n",
    "# Remove grafos sem arestas\n",
    "pyg_dataset = [g for g in pyg_dataset if g.num_edges > 0]      \n",
    "\n",
    "# convertendo p/ nx\n",
    "graphsg = []\n",
    "for i in range (len(pyg_dataset)):\n",
    "    # Adiciona grafo networkx \n",
    "    graphsg.append(utils.to_networkx(pyg_dataset[i]))\n",
    "    \n",
    "# Exemplo ilustrativo (primeiro grafo do dataset)\n",
    "plt.figure(figsize=(10,5))\n",
    "ax = plt.gca()\n",
    "ax.set_title('Ilustração exemplo do primeiro grafo do dataset')\n",
    "nx.draw_kamada_kawai(graphsg[0], with_labels=True, ax=ax)    \n",
    "\n",
    "# Converte os grafos para formato Deep Snap\n",
    "graphs = GraphDataset.pyg_to_graphs(pyg_dataset, netlib=nx)\n",
    "\n",
    "# Cria o objeto dataset Deep Snap\n",
    "dataset = GraphDataset(graphs, task=\"graph\", minimum_node_per_graph = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão em treino (80%), validação (10%) e teste (10%)\n",
    "datasets = {}\n",
    "datasets['train'], datasets['val'], datasets['test'] = dataset.split(\n",
    "            transductive=False, split_ratio = [0.8, 0.1, 0.1])\n",
    "\n",
    "# Geração do DataLoader com o tamanho do lote\n",
    "data = {split: DataLoader(\n",
    "                dataset, collate_fn=Batch.collate(), \n",
    "                batch_size=args.batch_size, shuffle=True)\n",
    "                for split, dataset in datasets.items()}\n",
    "\n",
    "# Variáveis de número de classes e de atributos dos vértices \n",
    "num_classes = datasets['train'].num_graph_labels\n",
    "num_node_features = datasets['train'].num_node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otimizador(args, params):\n",
    "    # Velocidade do decaimento\n",
    "    weight_decay = args.weight_decay\n",
    "    # Filtro de correção de gradiente p/ uma nova rede\n",
    "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
    "    # Otimizador Adam\n",
    "    optimizer = optim.Adam(filter_fn, lr=args.learningrate, weight_decay=weight_decay)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe da Rede de Isomorfismo de Grafos (GIN) \n",
    "class GIN(torch.nn.Module):\n",
    "    # Argumentos: dimensão de entrada, dimensão oculta, dimensão de saída e parâmetros \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args):\n",
    "        super(GIN, self).__init__()\n",
    "        # Quantidade de camadas\n",
    "        self.num_layers = args.num_layers\n",
    "        \n",
    "        # Cria a camada de entrada\n",
    "        self.pre_mp = nn.Sequential(\n",
    "                nn.Linear(input_dim, hidden_dim))\n",
    "\n",
    "        # Cria as camadas ocultas convolucionais GIN\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.nn1 = Sequential(Linear(hidden_dim, hidden_dim), ReLU(), Linear(hidden_dim, hidden_dim))\n",
    "        self.convs.append(pyg_nn.GINConv(self.nn1))\n",
    "        \n",
    "        for l in range(args.num_layers-1):\n",
    "            self.nnk = Sequential(Linear(hidden_dim, hidden_dim), ReLU(), Linear(hidden_dim, hidden_dim))\n",
    "            self.convs.append(pyg_nn.GINConv(self.nnk))\n",
    "\n",
    "        # Cria a camada de saída   \n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), ReLU(), nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    # Propagação    \n",
    "    def forward(self, data):\n",
    "        # Carregando dados de treino\n",
    "        x, edge_index, batch = data.node_feature, data.edge_index, data.batch\n",
    "        # Propagando X pela camada de entrada \n",
    "        x = self.pre_mp(x)\n",
    "        # Propagando pelas camadas ocultas\n",
    "        for i in range(len(self.convs)):\n",
    "            # Carregando edge_index e atualizando x pelas camadas ocultas\n",
    "            x = self.convs[i](x, edge_index)\n",
    "            # \"Filtrando\" pela ativação ReLU\n",
    "            x = F.relu(x)\n",
    "        # Camada de sum pooling dos vértices do grafo     \n",
    "        x = pyg_nn.global_add_pool(x, batch)\n",
    "        # Camada de saída\n",
    "        x = self.post_mp(x)\n",
    "        # \"Filtrando\" pela ativação softmax\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    # Função de perda dado o valor predito e real\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe da Rede Neural em Grafos (GNN) \n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, args):\n",
    "        super(GNN, self).__init__()\n",
    "        # Droupout\n",
    "        self.dropout = args.dropout\n",
    "        # Quantidade de camadas\n",
    "        self.num_layers = args.num_layers\n",
    "\n",
    "        # Cria a camada de entrada\n",
    "        conv_model = self.build_conv_model(args.modelo)\n",
    "        \n",
    "        # Cria as camadas ocultas convolucionais GNN\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
    "\n",
    "        for l in range(args.num_layers-1):\n",
    "            self.convs.append(conv_model(hidden_dim, hidden_dim))\n",
    "\n",
    "        # Cria a camada de saída    \n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Dropout(args.dropout), \n",
    "            ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "    # Verificação do tipo de GNN    \n",
    "    def build_conv_model(self, tipo_modelo):\n",
    "        if tipo_modelo == 'GCN':\n",
    "            return pyg_nn.GCNConv\n",
    "        elif tipo_modelo == 'GAT':\n",
    "       \t    return pyg_nn.GATConv\n",
    "        else:\n",
    "            raise ValueError(\"Modelo {} não está presente no GNN.build_conv_model.\".format(tipo_modelo))\n",
    "\n",
    "    # Propagação        \n",
    "    def forward(self, data):\n",
    "        # Carregando dados de treino\n",
    "        x, edge_index, batch = data.node_feature, data.edge_index, data.batch\n",
    "        # Propagando pelas camadas da rede\n",
    "        for i in range(len(self.convs)):\n",
    "            # Carregando edge_index e atualizando x pelas camadas ocultas \n",
    "            x = self.convs[i](x, edge_index)\n",
    "            # \"Filtrando\" pela ativação ReLU\n",
    "            x = F.relu(x)\n",
    "            # Executando dropout para \"esquecer\" neurônios\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # Camada de sum pooling dos vértices do grafo         \n",
    "        x = pyg_nn.global_add_pool(x, batch)\n",
    "        # Camada de saída\n",
    "        x = self.post_mp(x)\n",
    "        # \"Filtrando\" pela ativação softmax\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    # Função de perda dado o valor predito e real\n",
    "    def loss(self, pred, label):\n",
    "        return F.nll_loss(pred, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, test_loader, args, num_node_features, num_classes):\n",
    "    # Verificação do tipo de GNN    \n",
    "    if args.modelo == \"GIN\":\n",
    "        modeloesc = GIN\n",
    "    else:\n",
    "        modeloesc = GNN\n",
    "\n",
    "    # Inicializa o modelo escolhido    \n",
    "    modelo = modeloesc(num_node_features, args.hidden_dim, num_classes, args).to(\"cpu\")\n",
    "    # Inicializa o otimizador\n",
    "    opt = otimizador(args, modelo.parameters())\n",
    "\n",
    "    # Laço de épocas\n",
    "    for epoch in range(args.epocas):\n",
    "        # Perda acumulada\n",
    "        total_loss = 0\n",
    "        # Treino do modelo\n",
    "        modelo.train()\n",
    "        # Quantidade de grafos treinados\n",
    "        num_grafos = 0\n",
    "        # Para cada lote no conjunto de treino\n",
    "        for batch in train_loader:\n",
    "            # Device CPU\n",
    "            batch.to(\"cpu\")\n",
    "            # Inicializa gradiente 0\n",
    "            opt.zero_grad()\n",
    "            # Predição\n",
    "            pred = modelo(batch)\n",
    "            # Valor real correspondente\n",
    "            label = batch.graph_label\n",
    "            # Cálculo da perda\n",
    "            loss = modelo.loss(pred, label)\n",
    "            # Cálcula o gradiente\n",
    "            loss.backward()\n",
    "            # Atualiza os parâmetros do otimizador\n",
    "            opt.step()\n",
    "            # Incrementa a perda acumulada\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "            # Incrementa a quantidade de grafos treinados\n",
    "            num_grafos += batch.num_graphs\n",
    "        # Retorna a loss média por grafo\n",
    "        total_loss /= num_grafos\n",
    "\n",
    "        # Teste de acurácia de treino, teste e validação\n",
    "        train_acc = test(train_loader, modelo)\n",
    "        val_acc = test(val_loader, modelo)\n",
    "        test_acc = test(test_loader, modelo)\n",
    "        print(\"Época {}: Train: {:.4f}, Validation: {:.4f}. Test: {:.4f}, Loss: {:.4f}\".format(epoch + 1, train_acc, val_acc, test_acc, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, modelo):\n",
    "    # Modelo treinado\n",
    "    modelo.eval()\n",
    "\n",
    "    # Acertos da rede neural\n",
    "    corretos = 0\n",
    "    # Quantidade de grafos testados\n",
    "    num_grafos = 0\n",
    "    for batch in loader:\n",
    "        # Device CPU\n",
    "        batch.to(\"cpu\")\n",
    "        with torch.no_grad():\n",
    "            # Valor predito e real\n",
    "            pred = modelo(batch).max(dim=1)[1]\n",
    "            label = batch.graph_label\n",
    "        # Se forem iguais incrementa quantidade de acertos\n",
    "        corretos += pred.eq(label).sum().item()\n",
    "        # Incrementa a quantidade de grafos testados \n",
    "        num_grafos += batch.num_graphs\n",
    "    # Retorna a acurácia média por grafo\n",
    "    return corretos / num_grafos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1: Train: 0.2698, Validation: 0.2902. Test: 0.2356, Loss: 2.5370\n",
      "Época 2: Train: 0.4738, Validation: 0.4464. Test: 0.4489, Loss: 1.9155\n",
      "Época 3: Train: 0.5190, Validation: 0.5402. Test: 0.4844, Loss: 1.5328\n",
      "Época 4: Train: 0.7157, Validation: 0.7500. Test: 0.7156, Loss: 1.2356\n",
      "Época 5: Train: 0.7737, Validation: 0.8125. Test: 0.7867, Loss: 1.0467\n",
      "Época 6: Train: 0.8227, Validation: 0.8482. Test: 0.8311, Loss: 0.9294\n",
      "Época 7: Train: 0.7670, Validation: 0.7857. Test: 0.7956, Loss: 0.8276\n",
      "Época 8: Train: 0.7821, Validation: 0.8080. Test: 0.8178, Loss: 0.7699\n",
      "Época 9: Train: 0.8528, Validation: 0.8750. Test: 0.8711, Loss: 0.7034\n",
      "Época 10: Train: 0.8439, Validation: 0.8616. Test: 0.8444, Loss: 0.6503\n",
      "Época 11: Train: 0.8645, Validation: 0.8839. Test: 0.8711, Loss: 0.6142\n",
      "Época 12: Train: 0.8668, Validation: 0.8571. Test: 0.8622, Loss: 0.5626\n",
      "Época 13: Train: 0.8768, Validation: 0.8795. Test: 0.8800, Loss: 0.5937\n",
      "Época 14: Train: 0.8322, Validation: 0.8482. Test: 0.8622, Loss: 0.5237\n",
      "Época 15: Train: 0.8824, Validation: 0.8929. Test: 0.8711, Loss: 0.5214\n",
      "Época 16: Train: 0.8779, Validation: 0.9062. Test: 0.8889, Loss: 0.4609\n",
      "Época 17: Train: 0.8868, Validation: 0.9062. Test: 0.8889, Loss: 0.4408\n",
      "Época 18: Train: 0.8528, Validation: 0.8571. Test: 0.8578, Loss: 0.4448\n",
      "Época 19: Train: 0.8946, Validation: 0.9062. Test: 0.8933, Loss: 0.4183\n",
      "Época 20: Train: 0.9025, Validation: 0.9018. Test: 0.9111, Loss: 0.3860\n",
      "Época 21: Train: 0.8863, Validation: 0.8750. Test: 0.8622, Loss: 0.4036\n",
      "Época 22: Train: 0.8896, Validation: 0.8973. Test: 0.8711, Loss: 0.3719\n",
      "Época 23: Train: 0.9103, Validation: 0.9196. Test: 0.9244, Loss: 0.3585\n",
      "Época 24: Train: 0.9125, Validation: 0.9152. Test: 0.9067, Loss: 0.3370\n",
      "Época 25: Train: 0.9091, Validation: 0.9286. Test: 0.9111, Loss: 0.3222\n",
      "Época 26: Train: 0.9125, Validation: 0.9107. Test: 0.8889, Loss: 0.3241\n",
      "Época 27: Train: 0.8958, Validation: 0.9062. Test: 0.9200, Loss: 0.3130\n",
      "Época 28: Train: 0.9114, Validation: 0.9196. Test: 0.9244, Loss: 0.3049\n",
      "Época 29: Train: 0.9220, Validation: 0.9241. Test: 0.9067, Loss: 0.3018\n",
      "Época 30: Train: 0.8846, Validation: 0.8795. Test: 0.8978, Loss: 0.2843\n",
      "Época 31: Train: 0.9197, Validation: 0.9062. Test: 0.8889, Loss: 0.3209\n",
      "Época 32: Train: 0.9281, Validation: 0.9330. Test: 0.9333, Loss: 0.2859\n",
      "Época 33: Train: 0.9225, Validation: 0.9107. Test: 0.8978, Loss: 0.2813\n",
      "Época 34: Train: 0.9281, Validation: 0.9420. Test: 0.8978, Loss: 0.2645\n",
      "Época 35: Train: 0.9197, Validation: 0.9375. Test: 0.9244, Loss: 0.2582\n",
      "Época 36: Train: 0.9359, Validation: 0.9286. Test: 0.9111, Loss: 0.2563\n",
      "Época 37: Train: 0.9287, Validation: 0.9241. Test: 0.9111, Loss: 0.2538\n",
      "Época 38: Train: 0.9130, Validation: 0.9330. Test: 0.9067, Loss: 0.2305\n",
      "Época 39: Train: 0.9292, Validation: 0.9241. Test: 0.9067, Loss: 0.2667\n",
      "Época 40: Train: 0.9320, Validation: 0.9375. Test: 0.9022, Loss: 0.2447\n",
      "Época 41: Train: 0.9264, Validation: 0.9107. Test: 0.9111, Loss: 0.2185\n",
      "Época 42: Train: 0.9203, Validation: 0.9241. Test: 0.9022, Loss: 0.2428\n",
      "Época 43: Train: 0.9482, Validation: 0.9420. Test: 0.9200, Loss: 0.2287\n",
      "Época 44: Train: 0.9476, Validation: 0.9330. Test: 0.9422, Loss: 0.2003\n",
      "Época 45: Train: 0.9342, Validation: 0.9286. Test: 0.9333, Loss: 0.1950\n",
      "Época 46: Train: 0.9203, Validation: 0.8973. Test: 0.8933, Loss: 0.2306\n",
      "Época 47: Train: 0.9498, Validation: 0.9375. Test: 0.9200, Loss: 0.2135\n",
      "Época 48: Train: 0.9515, Validation: 0.9420. Test: 0.9378, Loss: 0.1840\n",
      "Época 49: Train: 0.9259, Validation: 0.9241. Test: 0.9111, Loss: 0.1898\n",
      "Época 50: Train: 0.9532, Validation: 0.9464. Test: 0.9244, Loss: 0.1936\n",
      "Época 51: Train: 0.9197, Validation: 0.9286. Test: 0.9156, Loss: 0.1899\n",
      "Época 52: Train: 0.9565, Validation: 0.9464. Test: 0.9289, Loss: 0.1952\n",
      "Época 53: Train: 0.9521, Validation: 0.9464. Test: 0.9378, Loss: 0.1759\n",
      "Época 54: Train: 0.9443, Validation: 0.9330. Test: 0.9289, Loss: 0.2000\n",
      "Época 55: Train: 0.9565, Validation: 0.9464. Test: 0.9289, Loss: 0.1747\n",
      "Época 56: Train: 0.9548, Validation: 0.9420. Test: 0.9244, Loss: 0.1781\n",
      "Época 57: Train: 0.9454, Validation: 0.9375. Test: 0.9244, Loss: 0.1846\n",
      "Época 58: Train: 0.9515, Validation: 0.9330. Test: 0.9156, Loss: 0.1486\n",
      "Época 59: Train: 0.9331, Validation: 0.9152. Test: 0.9111, Loss: 0.1943\n",
      "Época 60: Train: 0.9554, Validation: 0.9286. Test: 0.9200, Loss: 0.1621\n",
      "Época 61: Train: 0.9588, Validation: 0.9375. Test: 0.9244, Loss: 0.1651\n",
      "Época 62: Train: 0.9515, Validation: 0.9375. Test: 0.9244, Loss: 0.1612\n",
      "Época 63: Train: 0.9548, Validation: 0.9420. Test: 0.9289, Loss: 0.1481\n",
      "Época 64: Train: 0.9615, Validation: 0.9464. Test: 0.9156, Loss: 0.1397\n",
      "Época 65: Train: 0.9459, Validation: 0.9330. Test: 0.9333, Loss: 0.1614\n",
      "Época 66: Train: 0.9348, Validation: 0.8973. Test: 0.9067, Loss: 0.1551\n",
      "Época 67: Train: 0.9649, Validation: 0.9420. Test: 0.9289, Loss: 0.1452\n",
      "Época 68: Train: 0.9504, Validation: 0.9375. Test: 0.9378, Loss: 0.1398\n",
      "Época 69: Train: 0.9610, Validation: 0.9330. Test: 0.9289, Loss: 0.1397\n",
      "Época 70: Train: 0.9688, Validation: 0.9509. Test: 0.9244, Loss: 0.1273\n",
      "Época 71: Train: 0.9693, Validation: 0.9420. Test: 0.9244, Loss: 0.1202\n",
      "Época 72: Train: 0.9560, Validation: 0.9196. Test: 0.9156, Loss: 0.1207\n",
      "Época 73: Train: 0.9560, Validation: 0.9375. Test: 0.9467, Loss: 0.1380\n",
      "Época 74: Train: 0.9443, Validation: 0.9420. Test: 0.9556, Loss: 0.1448\n",
      "Época 75: Train: 0.9443, Validation: 0.9420. Test: 0.9067, Loss: 0.1309\n",
      "Época 76: Train: 0.9749, Validation: 0.9509. Test: 0.9422, Loss: 0.1349\n",
      "Época 77: Train: 0.9404, Validation: 0.9330. Test: 0.9067, Loss: 0.1127\n",
      "Época 78: Train: 0.9699, Validation: 0.9420. Test: 0.9111, Loss: 0.1247\n",
      "Época 79: Train: 0.9537, Validation: 0.9375. Test: 0.9333, Loss: 0.1327\n",
      "Época 80: Train: 0.9543, Validation: 0.9330. Test: 0.9111, Loss: 0.1337\n",
      "Época 81: Train: 0.9732, Validation: 0.9464. Test: 0.9289, Loss: 0.1297\n",
      "Época 82: Train: 0.9710, Validation: 0.9420. Test: 0.9511, Loss: 0.1162\n",
      "Época 83: Train: 0.9627, Validation: 0.9420. Test: 0.9156, Loss: 0.1062\n",
      "Época 84: Train: 0.9716, Validation: 0.9375. Test: 0.9422, Loss: 0.1378\n",
      "Época 85: Train: 0.9576, Validation: 0.9330. Test: 0.9422, Loss: 0.1137\n",
      "Época 86: Train: 0.9476, Validation: 0.9152. Test: 0.9156, Loss: 0.1427\n",
      "Época 87: Train: 0.9744, Validation: 0.9464. Test: 0.9333, Loss: 0.1080\n",
      "Época 88: Train: 0.9420, Validation: 0.9286. Test: 0.9200, Loss: 0.1256\n",
      "Época 89: Train: 0.9677, Validation: 0.9375. Test: 0.9244, Loss: 0.1163\n",
      "Época 90: Train: 0.9738, Validation: 0.9375. Test: 0.9333, Loss: 0.0956\n",
      "Época 91: Train: 0.9543, Validation: 0.9241. Test: 0.9244, Loss: 0.0973\n",
      "Época 92: Train: 0.9632, Validation: 0.9330. Test: 0.9244, Loss: 0.1174\n",
      "Época 93: Train: 0.9744, Validation: 0.9420. Test: 0.9333, Loss: 0.1650\n",
      "Época 94: Train: 0.9794, Validation: 0.9509. Test: 0.9333, Loss: 0.0887\n",
      "Época 95: Train: 0.9727, Validation: 0.9464. Test: 0.9422, Loss: 0.0912\n",
      "Época 96: Train: 0.9677, Validation: 0.9420. Test: 0.9378, Loss: 0.0938\n",
      "Época 97: Train: 0.9755, Validation: 0.9375. Test: 0.9378, Loss: 0.0893\n",
      "Época 98: Train: 0.9682, Validation: 0.9330. Test: 0.9200, Loss: 0.0904\n",
      "Época 99: Train: 0.9777, Validation: 0.9464. Test: 0.9333, Loss: 0.1017\n",
      "Época 100: Train: 0.9632, Validation: 0.9420. Test: 0.9289, Loss: 0.0849\n",
      "Época 101: Train: 0.9744, Validation: 0.9420. Test: 0.9378, Loss: 0.1079\n",
      "Época 102: Train: 0.9766, Validation: 0.9375. Test: 0.9378, Loss: 0.0901\n",
      "Época 103: Train: 0.9699, Validation: 0.9330. Test: 0.9467, Loss: 0.0783\n",
      "Época 104: Train: 0.9738, Validation: 0.9420. Test: 0.9244, Loss: 0.0771\n",
      "Época 105: Train: 0.9810, Validation: 0.9420. Test: 0.9378, Loss: 0.0835\n",
      "Época 106: Train: 0.9810, Validation: 0.9420. Test: 0.9600, Loss: 0.0741\n",
      "Época 107: Train: 0.9771, Validation: 0.9509. Test: 0.9422, Loss: 0.0673\n",
      "Época 108: Train: 0.9498, Validation: 0.9286. Test: 0.9111, Loss: 0.0905\n",
      "Época 109: Train: 0.9788, Validation: 0.9464. Test: 0.9289, Loss: 0.1137\n",
      "Época 110: Train: 0.9710, Validation: 0.9286. Test: 0.9556, Loss: 0.0900\n",
      "Época 111: Train: 0.9688, Validation: 0.9330. Test: 0.9467, Loss: 0.0674\n",
      "Época 112: Train: 0.9794, Validation: 0.9420. Test: 0.9111, Loss: 0.0877\n",
      "Época 113: Train: 0.9649, Validation: 0.9464. Test: 0.9467, Loss: 0.0673\n",
      "Época 114: Train: 0.9805, Validation: 0.9375. Test: 0.9289, Loss: 0.0896\n",
      "Época 115: Train: 0.9677, Validation: 0.9509. Test: 0.9289, Loss: 0.0688\n",
      "Época 116: Train: 0.9816, Validation: 0.9375. Test: 0.9244, Loss: 0.1108\n",
      "Época 117: Train: 0.9805, Validation: 0.9375. Test: 0.9378, Loss: 0.0651\n",
      "Época 118: Train: 0.9838, Validation: 0.9464. Test: 0.9378, Loss: 0.0677\n",
      "Época 119: Train: 0.9894, Validation: 0.9464. Test: 0.9467, Loss: 0.0958\n",
      "Época 120: Train: 0.9889, Validation: 0.9464. Test: 0.9422, Loss: 0.0669\n",
      "Época 121: Train: 0.9922, Validation: 0.9464. Test: 0.9422, Loss: 0.0701\n",
      "Época 122: Train: 0.9928, Validation: 0.9464. Test: 0.9333, Loss: 0.0545\n",
      "Época 123: Train: 0.9894, Validation: 0.9420. Test: 0.9511, Loss: 0.0475\n",
      "Época 124: Train: 0.9727, Validation: 0.9286. Test: 0.9333, Loss: 0.0910\n",
      "Época 125: Train: 0.9699, Validation: 0.9420. Test: 0.9600, Loss: 0.1710\n",
      "Época 126: Train: 0.9855, Validation: 0.9464. Test: 0.9556, Loss: 0.0606\n",
      "Época 127: Train: 0.9928, Validation: 0.9375. Test: 0.9467, Loss: 0.0550\n",
      "Época 128: Train: 0.9810, Validation: 0.9464. Test: 0.9333, Loss: 0.0536\n",
      "Época 129: Train: 0.9916, Validation: 0.9375. Test: 0.9600, Loss: 0.0556\n",
      "Época 130: Train: 0.9560, Validation: 0.9152. Test: 0.9067, Loss: 0.0767\n",
      "Época 131: Train: 0.9849, Validation: 0.9464. Test: 0.9333, Loss: 0.0900\n",
      "Época 132: Train: 0.9755, Validation: 0.9375. Test: 0.9422, Loss: 0.0596\n",
      "Época 133: Train: 0.9905, Validation: 0.9464. Test: 0.9511, Loss: 0.0511\n",
      "Época 134: Train: 0.9816, Validation: 0.9420. Test: 0.9244, Loss: 0.0715\n",
      "Época 135: Train: 0.9861, Validation: 0.9464. Test: 0.9156, Loss: 0.0784\n",
      "Época 136: Train: 0.9889, Validation: 0.9375. Test: 0.9556, Loss: 0.0673\n",
      "Época 137: Train: 0.9905, Validation: 0.9420. Test: 0.9556, Loss: 0.0405\n",
      "Época 138: Train: 0.9822, Validation: 0.9241. Test: 0.9289, Loss: 0.0493\n",
      "Época 139: Train: 0.9838, Validation: 0.9464. Test: 0.9600, Loss: 0.0562\n",
      "Época 140: Train: 0.9889, Validation: 0.9330. Test: 0.9289, Loss: 0.0478\n",
      "Época 141: Train: 0.9716, Validation: 0.9330. Test: 0.9378, Loss: 0.0534\n",
      "Época 142: Train: 0.9693, Validation: 0.9375. Test: 0.9378, Loss: 0.0647\n",
      "Época 143: Train: 0.9543, Validation: 0.9241. Test: 0.9333, Loss: 0.0603\n",
      "Época 144: Train: 0.9911, Validation: 0.9420. Test: 0.9289, Loss: 0.0674\n",
      "Época 145: Train: 0.9861, Validation: 0.9509. Test: 0.9289, Loss: 0.0386\n",
      "Época 146: Train: 0.9900, Validation: 0.9464. Test: 0.9467, Loss: 0.0356\n",
      "Época 147: Train: 0.9727, Validation: 0.9375. Test: 0.9244, Loss: 0.0593\n",
      "Época 148: Train: 0.9822, Validation: 0.9464. Test: 0.9378, Loss: 0.0828\n",
      "Época 149: Train: 0.9794, Validation: 0.9286. Test: 0.9600, Loss: 0.0479\n",
      "Época 150: Train: 0.9833, Validation: 0.9420. Test: 0.9467, Loss: 0.0533\n",
      "Época 151: Train: 0.9738, Validation: 0.9554. Test: 0.9556, Loss: 0.0547\n",
      "Época 152: Train: 0.9755, Validation: 0.9420. Test: 0.9156, Loss: 0.0589\n",
      "Época 153: Train: 0.9844, Validation: 0.9375. Test: 0.9200, Loss: 0.0544\n",
      "Época 154: Train: 0.9950, Validation: 0.9464. Test: 0.9378, Loss: 0.0344\n",
      "Época 155: Train: 0.9889, Validation: 0.9464. Test: 0.9556, Loss: 0.0373\n",
      "Época 156: Train: 0.9944, Validation: 0.9420. Test: 0.9511, Loss: 0.0397\n",
      "Época 157: Train: 0.9933, Validation: 0.9464. Test: 0.9378, Loss: 0.0268\n",
      "Época 158: Train: 0.9766, Validation: 0.9196. Test: 0.9200, Loss: 0.0334\n",
      "Época 159: Train: 0.9766, Validation: 0.9286. Test: 0.9333, Loss: 0.0597\n",
      "Época 160: Train: 0.9543, Validation: 0.9107. Test: 0.9200, Loss: 0.0858\n",
      "Época 161: Train: 0.9877, Validation: 0.9330. Test: 0.9333, Loss: 0.0773\n",
      "Época 162: Train: 0.9872, Validation: 0.9286. Test: 0.9289, Loss: 0.0688\n",
      "Época 163: Train: 0.9671, Validation: 0.9107. Test: 0.9200, Loss: 0.0681\n",
      "Época 164: Train: 0.9928, Validation: 0.9420. Test: 0.9422, Loss: 0.0448\n",
      "Época 165: Train: 0.9911, Validation: 0.9375. Test: 0.9556, Loss: 0.0943\n",
      "Época 166: Train: 0.9961, Validation: 0.9420. Test: 0.9422, Loss: 0.0324\n",
      "Época 167: Train: 0.9955, Validation: 0.9464. Test: 0.9422, Loss: 0.0354\n",
      "Época 168: Train: 0.9944, Validation: 0.9330. Test: 0.9556, Loss: 0.0298\n",
      "Época 169: Train: 0.9944, Validation: 0.9464. Test: 0.9511, Loss: 0.0264\n",
      "Época 170: Train: 0.9928, Validation: 0.9375. Test: 0.9600, Loss: 0.0316\n",
      "Época 171: Train: 0.9939, Validation: 0.9464. Test: 0.9556, Loss: 0.0224\n",
      "Época 172: Train: 0.9916, Validation: 0.9464. Test: 0.9422, Loss: 0.0286\n",
      "Época 173: Train: 0.9392, Validation: 0.9241. Test: 0.9067, Loss: 0.0617\n",
      "Época 174: Train: 0.9855, Validation: 0.9375. Test: 0.9467, Loss: 0.0748\n",
      "Época 175: Train: 0.9928, Validation: 0.9420. Test: 0.9467, Loss: 0.0399\n",
      "Época 176: Train: 0.9928, Validation: 0.9375. Test: 0.9511, Loss: 0.0688\n",
      "Época 177: Train: 0.9955, Validation: 0.9464. Test: 0.9467, Loss: 0.0241\n",
      "Época 178: Train: 0.9972, Validation: 0.9330. Test: 0.9422, Loss: 0.0221\n",
      "Época 179: Train: 0.9972, Validation: 0.9375. Test: 0.9511, Loss: 0.0262\n",
      "Época 180: Train: 0.9978, Validation: 0.9420. Test: 0.9467, Loss: 0.0173\n",
      "Época 181: Train: 0.9972, Validation: 0.9375. Test: 0.9378, Loss: 0.0160\n",
      "Época 182: Train: 0.9833, Validation: 0.9375. Test: 0.9422, Loss: 0.0415\n",
      "Época 183: Train: 0.9710, Validation: 0.9420. Test: 0.9289, Loss: 0.0802\n",
      "Época 184: Train: 0.9928, Validation: 0.9464. Test: 0.9467, Loss: 0.0593\n",
      "Época 185: Train: 0.9861, Validation: 0.9286. Test: 0.9289, Loss: 0.0308\n",
      "Época 186: Train: 0.9905, Validation: 0.9420. Test: 0.9378, Loss: 0.0462\n",
      "Época 187: Train: 0.9967, Validation: 0.9464. Test: 0.9289, Loss: 0.0403\n",
      "Época 188: Train: 0.9961, Validation: 0.9375. Test: 0.9600, Loss: 0.0193\n",
      "Época 189: Train: 0.9922, Validation: 0.9464. Test: 0.9556, Loss: 0.0253\n",
      "Época 190: Train: 0.9961, Validation: 0.9375. Test: 0.9467, Loss: 0.0250\n",
      "Época 191: Train: 0.9972, Validation: 0.9464. Test: 0.9378, Loss: 0.0165\n",
      "Época 192: Train: 0.9621, Validation: 0.9152. Test: 0.9244, Loss: 0.0312\n",
      "Época 193: Train: 0.9794, Validation: 0.9509. Test: 0.9378, Loss: 0.1609\n",
      "Época 194: Train: 0.9788, Validation: 0.9286. Test: 0.9333, Loss: 0.1240\n",
      "Época 195: Train: 0.9933, Validation: 0.9420. Test: 0.9378, Loss: 0.0378\n",
      "Época 196: Train: 0.9900, Validation: 0.9464. Test: 0.9511, Loss: 0.0323\n",
      "Época 197: Train: 0.9955, Validation: 0.9420. Test: 0.9467, Loss: 0.0219\n",
      "Época 198: Train: 0.9928, Validation: 0.9420. Test: 0.9511, Loss: 0.0210\n",
      "Época 199: Train: 0.9978, Validation: 0.9330. Test: 0.9644, Loss: 0.0201\n",
      "Época 200: Train: 0.9972, Validation: 0.9330. Test: 0.9467, Loss: 0.0184\n",
      "Época 201: Train: 0.9978, Validation: 0.9375. Test: 0.9511, Loss: 0.0149\n",
      "Época 202: Train: 0.9983, Validation: 0.9420. Test: 0.9467, Loss: 0.0119\n",
      "Época 203: Train: 0.9905, Validation: 0.9464. Test: 0.9289, Loss: 0.0187\n",
      "Época 204: Train: 0.9905, Validation: 0.9464. Test: 0.9333, Loss: 0.0294\n",
      "Época 205: Train: 0.9794, Validation: 0.9241. Test: 0.9333, Loss: 0.1066\n",
      "Época 206: Train: 0.9827, Validation: 0.9330. Test: 0.9289, Loss: 0.0388\n",
      "Época 207: Train: 0.9916, Validation: 0.9420. Test: 0.9511, Loss: 0.0581\n",
      "Época 208: Train: 0.9955, Validation: 0.9420. Test: 0.9467, Loss: 0.0212\n",
      "Época 209: Train: 0.9978, Validation: 0.9420. Test: 0.9378, Loss: 0.0194\n",
      "Época 210: Train: 0.9983, Validation: 0.9420. Test: 0.9511, Loss: 0.0174\n",
      "Época 211: Train: 0.9983, Validation: 0.9375. Test: 0.9378, Loss: 0.0142\n",
      "Época 212: Train: 0.9967, Validation: 0.9375. Test: 0.9378, Loss: 0.0145\n",
      "Época 213: Train: 0.9922, Validation: 0.9375. Test: 0.9378, Loss: 0.0132\n",
      "Época 214: Train: 0.9805, Validation: 0.9286. Test: 0.9422, Loss: 0.0450\n",
      "Época 215: Train: 0.9833, Validation: 0.9375. Test: 0.9289, Loss: 0.0927\n",
      "Época 216: Train: 0.9911, Validation: 0.9286. Test: 0.9467, Loss: 0.0587\n",
      "Época 217: Train: 0.9877, Validation: 0.9375. Test: 0.9511, Loss: 0.0388\n",
      "Época 218: Train: 0.9894, Validation: 0.9375. Test: 0.9378, Loss: 0.0496\n",
      "Época 219: Train: 0.9944, Validation: 0.9330. Test: 0.9378, Loss: 0.0341\n",
      "Época 220: Train: 0.9967, Validation: 0.9420. Test: 0.9467, Loss: 0.0232\n",
      "Época 221: Train: 0.9983, Validation: 0.9464. Test: 0.9511, Loss: 0.0216\n",
      "Época 222: Train: 0.9983, Validation: 0.9464. Test: 0.9378, Loss: 0.0166\n",
      "Época 223: Train: 0.9978, Validation: 0.9375. Test: 0.9467, Loss: 0.0230\n",
      "Época 224: Train: 0.9983, Validation: 0.9464. Test: 0.9467, Loss: 0.0171\n",
      "Época 225: Train: 0.9983, Validation: 0.9420. Test: 0.9511, Loss: 0.0102\n",
      "Época 226: Train: 0.9989, Validation: 0.9375. Test: 0.9467, Loss: 0.0109\n",
      "Época 227: Train: 0.9978, Validation: 0.9464. Test: 0.9511, Loss: 0.0107\n",
      "Época 228: Train: 0.9944, Validation: 0.9375. Test: 0.9422, Loss: 0.0149\n",
      "Época 229: Train: 0.9716, Validation: 0.9241. Test: 0.9333, Loss: 0.0491\n",
      "Época 230: Train: 0.9916, Validation: 0.9375. Test: 0.9511, Loss: 0.0942\n",
      "Época 231: Train: 0.9950, Validation: 0.9420. Test: 0.9556, Loss: 0.0406\n",
      "Época 232: Train: 0.9922, Validation: 0.9330. Test: 0.9511, Loss: 0.0745\n",
      "Época 233: Train: 0.9978, Validation: 0.9554. Test: 0.9556, Loss: 0.0257\n",
      "Época 234: Train: 0.9961, Validation: 0.9509. Test: 0.9556, Loss: 0.0253\n",
      "Época 235: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0136\n",
      "Época 236: Train: 0.9989, Validation: 0.9509. Test: 0.9422, Loss: 0.0104\n",
      "Época 237: Train: 0.9978, Validation: 0.9375. Test: 0.9556, Loss: 0.0092\n",
      "Época 238: Train: 0.9989, Validation: 0.9420. Test: 0.9511, Loss: 0.0107\n",
      "Época 239: Train: 0.9978, Validation: 0.9464. Test: 0.9556, Loss: 0.0114\n",
      "Época 240: Train: 0.9989, Validation: 0.9509. Test: 0.9556, Loss: 0.0095\n",
      "Época 241: Train: 0.9760, Validation: 0.9375. Test: 0.9289, Loss: 0.0211\n",
      "Época 242: Train: 0.9872, Validation: 0.9375. Test: 0.9422, Loss: 0.0976\n",
      "Época 243: Train: 0.9799, Validation: 0.9375. Test: 0.9511, Loss: 0.0374\n",
      "Época 244: Train: 0.9710, Validation: 0.9241. Test: 0.9333, Loss: 0.0419\n",
      "Época 245: Train: 0.9989, Validation: 0.9464. Test: 0.9511, Loss: 0.0272\n",
      "Época 246: Train: 0.9983, Validation: 0.9464. Test: 0.9511, Loss: 0.0095\n",
      "Época 247: Train: 0.9989, Validation: 0.9464. Test: 0.9511, Loss: 0.0096\n",
      "Época 248: Train: 0.9989, Validation: 0.9464. Test: 0.9422, Loss: 0.0091\n",
      "Época 249: Train: 0.9989, Validation: 0.9464. Test: 0.9600, Loss: 0.0079\n",
      "Época 250: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0078\n",
      "Época 251: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0085\n",
      "Época 252: Train: 0.9967, Validation: 0.9420. Test: 0.9467, Loss: 0.0096\n",
      "Época 253: Train: 0.9827, Validation: 0.9330. Test: 0.9467, Loss: 0.0676\n",
      "Época 254: Train: 0.9950, Validation: 0.9464. Test: 0.9467, Loss: 0.0311\n",
      "Época 255: Train: 0.9638, Validation: 0.9196. Test: 0.9422, Loss: 0.0756\n",
      "Época 256: Train: 0.9972, Validation: 0.9420. Test: 0.9600, Loss: 0.1010\n",
      "Época 257: Train: 0.9983, Validation: 0.9464. Test: 0.9600, Loss: 0.0148\n",
      "Época 258: Train: 0.9983, Validation: 0.9420. Test: 0.9600, Loss: 0.0116\n",
      "Época 259: Train: 0.9989, Validation: 0.9375. Test: 0.9511, Loss: 0.0104\n",
      "Época 260: Train: 0.9994, Validation: 0.9509. Test: 0.9600, Loss: 0.0095\n",
      "Época 261: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0089\n",
      "Época 262: Train: 0.9994, Validation: 0.9509. Test: 0.9556, Loss: 0.0083\n",
      "Época 263: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0082\n",
      "Época 264: Train: 0.9967, Validation: 0.9464. Test: 0.9556, Loss: 0.0092\n",
      "Época 265: Train: 0.9766, Validation: 0.9330. Test: 0.9467, Loss: 0.0418\n",
      "Época 266: Train: 0.9732, Validation: 0.9286. Test: 0.9200, Loss: 0.1199\n",
      "Época 267: Train: 0.9916, Validation: 0.9464. Test: 0.9422, Loss: 0.0367\n",
      "Época 268: Train: 0.9928, Validation: 0.9464. Test: 0.9422, Loss: 0.0461\n",
      "Época 269: Train: 0.9983, Validation: 0.9464. Test: 0.9467, Loss: 0.0151\n",
      "Época 270: Train: 0.9989, Validation: 0.9375. Test: 0.9644, Loss: 0.0092\n",
      "Época 271: Train: 0.9989, Validation: 0.9464. Test: 0.9556, Loss: 0.0081\n",
      "Época 272: Train: 0.9989, Validation: 0.9420. Test: 0.9467, Loss: 0.0078\n",
      "Época 273: Train: 0.9978, Validation: 0.9509. Test: 0.9422, Loss: 0.0080\n",
      "Época 274: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0092\n",
      "Época 275: Train: 0.9989, Validation: 0.9464. Test: 0.9511, Loss: 0.0066\n",
      "Época 276: Train: 0.9994, Validation: 0.9509. Test: 0.9556, Loss: 0.0062\n",
      "Época 277: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0083\n",
      "Época 278: Train: 0.9894, Validation: 0.9330. Test: 0.9511, Loss: 0.1268\n",
      "Época 279: Train: 0.9961, Validation: 0.9509. Test: 0.9511, Loss: 0.1181\n",
      "Época 280: Train: 0.9972, Validation: 0.9464. Test: 0.9467, Loss: 0.0205\n",
      "Época 281: Train: 0.9989, Validation: 0.9464. Test: 0.9511, Loss: 0.0137\n",
      "Época 282: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0099\n",
      "Época 283: Train: 0.9989, Validation: 0.9464. Test: 0.9467, Loss: 0.0091\n",
      "Época 284: Train: 0.9989, Validation: 0.9464. Test: 0.9467, Loss: 0.0077\n",
      "Época 285: Train: 0.9989, Validation: 0.9509. Test: 0.9467, Loss: 0.0085\n",
      "Época 286: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0076\n",
      "Época 287: Train: 0.9989, Validation: 0.9554. Test: 0.9511, Loss: 0.0074\n",
      "Época 288: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0066\n",
      "Época 289: Train: 0.9989, Validation: 0.9420. Test: 0.9511, Loss: 0.0074\n",
      "Época 290: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0067\n",
      "Época 291: Train: 0.9972, Validation: 0.9554. Test: 0.9333, Loss: 0.0076\n",
      "Época 292: Train: 0.9521, Validation: 0.9062. Test: 0.9067, Loss: 0.0151\n",
      "Época 293: Train: 0.9515, Validation: 0.9241. Test: 0.9022, Loss: 0.0706\n",
      "Época 294: Train: 0.9905, Validation: 0.9554. Test: 0.9422, Loss: 0.0819\n",
      "Época 295: Train: 0.9983, Validation: 0.9509. Test: 0.9600, Loss: 0.0299\n",
      "Época 296: Train: 0.9967, Validation: 0.9554. Test: 0.9422, Loss: 0.0252\n",
      "Época 297: Train: 0.9989, Validation: 0.9554. Test: 0.9556, Loss: 0.0119\n",
      "Época 298: Train: 0.9994, Validation: 0.9509. Test: 0.9378, Loss: 0.0101\n",
      "Época 299: Train: 0.9989, Validation: 0.9464. Test: 0.9378, Loss: 0.0070\n",
      "Época 300: Train: 0.9983, Validation: 0.9509. Test: 0.9422, Loss: 0.0071\n",
      "Época 301: Train: 0.9989, Validation: 0.9464. Test: 0.9333, Loss: 0.0072\n",
      "Época 302: Train: 0.9978, Validation: 0.9509. Test: 0.9289, Loss: 0.0085\n",
      "Época 303: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0070\n",
      "Época 304: Train: 0.9978, Validation: 0.9464. Test: 0.9467, Loss: 0.0079\n",
      "Época 305: Train: 0.9816, Validation: 0.9464. Test: 0.9378, Loss: 0.0804\n",
      "Época 306: Train: 0.9928, Validation: 0.9464. Test: 0.9378, Loss: 0.0691\n",
      "Época 307: Train: 0.9978, Validation: 0.9420. Test: 0.9422, Loss: 0.0393\n",
      "Época 308: Train: 0.9983, Validation: 0.9464. Test: 0.9467, Loss: 0.0109\n",
      "Época 309: Train: 0.9983, Validation: 0.9464. Test: 0.9467, Loss: 0.0085\n",
      "Época 310: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0094\n",
      "Época 311: Train: 0.9994, Validation: 0.9464. Test: 0.9467, Loss: 0.0105\n",
      "Época 312: Train: 0.9989, Validation: 0.9420. Test: 0.9511, Loss: 0.0088\n",
      "Época 313: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0082\n",
      "Época 314: Train: 0.9989, Validation: 0.9464. Test: 0.9511, Loss: 0.0070\n",
      "Época 315: Train: 0.9983, Validation: 0.9464. Test: 0.9467, Loss: 0.0064\n",
      "Época 316: Train: 0.9994, Validation: 0.9509. Test: 0.9556, Loss: 0.0091\n",
      "Época 317: Train: 0.9994, Validation: 0.9464. Test: 0.9467, Loss: 0.0076\n",
      "Época 318: Train: 0.9994, Validation: 0.9464. Test: 0.9467, Loss: 0.0067\n",
      "Época 319: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0077\n",
      "Época 320: Train: 0.9381, Validation: 0.9018. Test: 0.9111, Loss: 0.1660\n",
      "Época 321: Train: 0.9855, Validation: 0.9420. Test: 0.9467, Loss: 0.1345\n",
      "Época 322: Train: 0.9967, Validation: 0.9509. Test: 0.9511, Loss: 0.0273\n",
      "Época 323: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0166\n",
      "Época 324: Train: 0.9989, Validation: 0.9509. Test: 0.9556, Loss: 0.0102\n",
      "Época 325: Train: 0.9994, Validation: 0.9509. Test: 0.9422, Loss: 0.0085\n",
      "Época 326: Train: 0.9989, Validation: 0.9554. Test: 0.9600, Loss: 0.0073\n",
      "Época 327: Train: 0.9994, Validation: 0.9509. Test: 0.9422, Loss: 0.0084\n",
      "Época 328: Train: 0.9994, Validation: 0.9464. Test: 0.9467, Loss: 0.0077\n",
      "Época 329: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0070\n",
      "Época 330: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0063\n",
      "Época 331: Train: 0.9994, Validation: 0.9509. Test: 0.9422, Loss: 0.0062\n",
      "Época 332: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0066\n",
      "Época 333: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0054\n",
      "Época 334: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0056\n",
      "Época 335: Train: 0.9994, Validation: 0.9464. Test: 0.9467, Loss: 0.0076\n",
      "Época 336: Train: 0.9961, Validation: 0.9598. Test: 0.9467, Loss: 0.0097\n",
      "Época 337: Train: 0.9855, Validation: 0.9598. Test: 0.9422, Loss: 0.1630\n",
      "Época 338: Train: 0.9972, Validation: 0.9420. Test: 0.9467, Loss: 0.0521\n",
      "Época 339: Train: 0.9989, Validation: 0.9554. Test: 0.9467, Loss: 0.0120\n",
      "Época 340: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0098\n",
      "Época 341: Train: 0.9994, Validation: 0.9509. Test: 0.9556, Loss: 0.0076\n",
      "Época 342: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0074\n",
      "Época 343: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0069\n",
      "Época 344: Train: 0.9994, Validation: 0.9509. Test: 0.9422, Loss: 0.0071\n",
      "Época 345: Train: 0.9928, Validation: 0.9330. Test: 0.9422, Loss: 0.1071\n",
      "Época 346: Train: 0.9950, Validation: 0.9420. Test: 0.9467, Loss: 0.0282\n",
      "Época 347: Train: 0.9989, Validation: 0.9420. Test: 0.9511, Loss: 0.0167\n",
      "Época 348: Train: 0.9989, Validation: 0.9509. Test: 0.9422, Loss: 0.0079\n",
      "Época 349: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0070\n",
      "Época 350: Train: 0.9994, Validation: 0.9464. Test: 0.9422, Loss: 0.0060\n",
      "Época 351: Train: 0.9994, Validation: 0.9464. Test: 0.9467, Loss: 0.0067\n",
      "Época 352: Train: 0.9989, Validation: 0.9509. Test: 0.9422, Loss: 0.0055\n",
      "Época 353: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0079\n",
      "Época 354: Train: 0.9989, Validation: 0.9420. Test: 0.9422, Loss: 0.0062\n",
      "Época 355: Train: 0.9989, Validation: 0.9464. Test: 0.9422, Loss: 0.0055\n",
      "Época 356: Train: 0.9571, Validation: 0.9286. Test: 0.9156, Loss: 0.0766\n",
      "Época 357: Train: 0.9928, Validation: 0.9420. Test: 0.9333, Loss: 0.0903\n",
      "Época 358: Train: 0.9994, Validation: 0.9554. Test: 0.9467, Loss: 0.0171\n",
      "Época 359: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0093\n",
      "Época 360: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0079\n",
      "Época 361: Train: 0.9994, Validation: 0.9554. Test: 0.9467, Loss: 0.0064\n",
      "Época 362: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0062\n",
      "Época 363: Train: 0.9994, Validation: 0.9464. Test: 0.9467, Loss: 0.0068\n",
      "Época 364: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0058\n",
      "Época 365: Train: 0.9994, Validation: 0.9509. Test: 0.9378, Loss: 0.0055\n",
      "Época 366: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0065\n",
      "Época 367: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0058\n",
      "Época 368: Train: 0.9972, Validation: 0.9509. Test: 0.9333, Loss: 0.0083\n",
      "Época 369: Train: 0.9710, Validation: 0.9420. Test: 0.9467, Loss: 0.1142\n",
      "Época 370: Train: 0.9944, Validation: 0.9598. Test: 0.9511, Loss: 0.0481\n",
      "Época 371: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0188\n",
      "Época 372: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0082\n",
      "Época 373: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0073\n",
      "Época 374: Train: 0.9989, Validation: 0.9464. Test: 0.9422, Loss: 0.0071\n",
      "Época 375: Train: 0.9994, Validation: 0.9420. Test: 0.9556, Loss: 0.0061\n",
      "Época 376: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0065\n",
      "Época 377: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0053\n",
      "Época 378: Train: 0.9994, Validation: 0.9420. Test: 0.9467, Loss: 0.0056\n",
      "Época 379: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0097\n",
      "Época 380: Train: 0.9989, Validation: 0.9464. Test: 0.9467, Loss: 0.0068\n",
      "Época 381: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0053\n",
      "Época 382: Train: 0.9989, Validation: 0.9509. Test: 0.9556, Loss: 0.0053\n",
      "Época 383: Train: 0.9994, Validation: 0.9509. Test: 0.9378, Loss: 0.0065\n",
      "Época 384: Train: 0.9281, Validation: 0.9018. Test: 0.8978, Loss: 0.0208\n",
      "Época 385: Train: 0.9827, Validation: 0.9420. Test: 0.9378, Loss: 0.1398\n",
      "Época 386: Train: 0.9972, Validation: 0.9464. Test: 0.9556, Loss: 0.0570\n",
      "Época 387: Train: 0.9994, Validation: 0.9464. Test: 0.9378, Loss: 0.0182\n",
      "Época 388: Train: 0.9989, Validation: 0.9464. Test: 0.9600, Loss: 0.0093\n",
      "Época 389: Train: 0.9989, Validation: 0.9464. Test: 0.9467, Loss: 0.0069\n",
      "Época 390: Train: 0.9994, Validation: 0.9464. Test: 0.9600, Loss: 0.0152\n",
      "Época 391: Train: 0.9989, Validation: 0.9509. Test: 0.9600, Loss: 0.0070\n",
      "Época 392: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0057\n",
      "Época 393: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0057\n",
      "Época 394: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0051\n",
      "Época 395: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0048\n",
      "Época 396: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0062\n",
      "Época 397: Train: 0.9994, Validation: 0.9464. Test: 0.9600, Loss: 0.0047\n",
      "Época 398: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0046\n",
      "Época 399: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0044\n",
      "Época 400: Train: 0.9989, Validation: 0.9509. Test: 0.9467, Loss: 0.0047\n",
      "Época 401: Train: 0.9994, Validation: 0.9509. Test: 0.9600, Loss: 0.0063\n",
      "Época 402: Train: 0.9588, Validation: 0.9420. Test: 0.9244, Loss: 0.0702\n",
      "Época 403: Train: 0.9944, Validation: 0.9554. Test: 0.9556, Loss: 0.0432\n",
      "Época 404: Train: 0.9849, Validation: 0.9286. Test: 0.9244, Loss: 0.0311\n",
      "Época 405: Train: 0.9972, Validation: 0.9509. Test: 0.9467, Loss: 0.0424\n",
      "Época 406: Train: 0.9989, Validation: 0.9464. Test: 0.9422, Loss: 0.0163\n",
      "Época 407: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0075\n",
      "Época 408: Train: 0.9994, Validation: 0.9509. Test: 0.9556, Loss: 0.0061\n",
      "Época 409: Train: 0.9994, Validation: 0.9464. Test: 0.9600, Loss: 0.0050\n",
      "Época 410: Train: 0.9950, Validation: 0.9420. Test: 0.9422, Loss: 0.0056\n",
      "Época 411: Train: 0.9994, Validation: 0.9464. Test: 0.9600, Loss: 0.0051\n",
      "Época 412: Train: 0.9989, Validation: 0.9464. Test: 0.9511, Loss: 0.0051\n",
      "Época 413: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0046\n",
      "Época 414: Train: 0.9989, Validation: 0.9509. Test: 0.9556, Loss: 0.0063\n",
      "Época 415: Train: 0.9900, Validation: 0.9464. Test: 0.9422, Loss: 0.0082\n",
      "Época 416: Train: 0.9465, Validation: 0.9286. Test: 0.9200, Loss: 0.1631\n",
      "Época 417: Train: 0.9983, Validation: 0.9464. Test: 0.9511, Loss: 0.0566\n",
      "Época 418: Train: 0.9994, Validation: 0.9509. Test: 0.9600, Loss: 0.0111\n",
      "Época 419: Train: 0.9989, Validation: 0.9509. Test: 0.9600, Loss: 0.0082\n",
      "Época 420: Train: 0.9989, Validation: 0.9509. Test: 0.9600, Loss: 0.0068\n",
      "Época 421: Train: 0.9989, Validation: 0.9509. Test: 0.9600, Loss: 0.0062\n",
      "Época 422: Train: 0.9989, Validation: 0.9554. Test: 0.9467, Loss: 0.0064\n",
      "Época 423: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0056\n",
      "Época 424: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0056\n",
      "Época 425: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0048\n",
      "Época 426: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0046\n",
      "Época 427: Train: 0.9989, Validation: 0.9509. Test: 0.9600, Loss: 0.0044\n",
      "Época 428: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0043\n",
      "Época 429: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0046\n",
      "Época 430: Train: 0.9994, Validation: 0.9509. Test: 0.9556, Loss: 0.0051\n",
      "Época 431: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0051\n",
      "Época 432: Train: 0.9989, Validation: 0.9509. Test: 0.9556, Loss: 0.0044\n",
      "Época 433: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0058\n",
      "Época 434: Train: 1.0000, Validation: 0.9554. Test: 0.9556, Loss: 0.0050\n",
      "Época 435: Train: 0.9994, Validation: 0.9420. Test: 0.9422, Loss: 0.0063\n",
      "Época 436: Train: 0.9671, Validation: 0.9464. Test: 0.9244, Loss: 0.0098\n",
      "Época 437: Train: 0.9822, Validation: 0.9554. Test: 0.9467, Loss: 0.1143\n",
      "Época 438: Train: 0.9994, Validation: 0.9509. Test: 0.9600, Loss: 0.0408\n",
      "Época 439: Train: 0.9989, Validation: 0.9554. Test: 0.9556, Loss: 0.0094\n",
      "Época 440: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0066\n",
      "Época 441: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0054\n",
      "Época 442: Train: 0.9989, Validation: 0.9509. Test: 0.9556, Loss: 0.0054\n",
      "Época 443: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0055\n",
      "Época 444: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0050\n",
      "Época 445: Train: 0.9994, Validation: 0.9509. Test: 0.9556, Loss: 0.0047\n",
      "Época 446: Train: 0.9994, Validation: 0.9598. Test: 0.9511, Loss: 0.0048\n",
      "Época 447: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0041\n",
      "Época 448: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0050\n",
      "Época 449: Train: 0.9994, Validation: 0.9598. Test: 0.9556, Loss: 0.0041\n",
      "Época 450: Train: 1.0000, Validation: 0.9554. Test: 0.9511, Loss: 0.0053\n",
      "Época 451: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0041\n",
      "Época 452: Train: 1.0000, Validation: 0.9509. Test: 0.9467, Loss: 0.0038\n",
      "Época 453: Train: 0.9900, Validation: 0.9375. Test: 0.9422, Loss: 0.0130\n",
      "Época 454: Train: 0.9894, Validation: 0.9420. Test: 0.9422, Loss: 0.1154\n",
      "Época 455: Train: 0.9944, Validation: 0.9509. Test: 0.9378, Loss: 0.0296\n",
      "Época 456: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0158\n",
      "Época 457: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0072\n",
      "Época 458: Train: 1.0000, Validation: 0.9509. Test: 0.9511, Loss: 0.0067\n",
      "Época 459: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0056\n",
      "Época 460: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0052\n",
      "Época 461: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0050\n",
      "Época 462: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0046\n",
      "Época 463: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0041\n",
      "Época 464: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0040\n",
      "Época 465: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0043\n",
      "Época 466: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0043\n",
      "Época 467: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0041\n",
      "Época 468: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0042\n",
      "Época 469: Train: 0.9861, Validation: 0.9375. Test: 0.9333, Loss: 0.0078\n",
      "Época 470: Train: 0.9721, Validation: 0.9286. Test: 0.9289, Loss: 0.2233\n",
      "Época 471: Train: 0.9989, Validation: 0.9420. Test: 0.9333, Loss: 0.0606\n",
      "Época 472: Train: 0.9994, Validation: 0.9464. Test: 0.9511, Loss: 0.0144\n",
      "Época 473: Train: 0.9983, Validation: 0.9464. Test: 0.9422, Loss: 0.0083\n",
      "Época 474: Train: 0.9989, Validation: 0.9509. Test: 0.9511, Loss: 0.0076\n",
      "Época 475: Train: 0.9994, Validation: 0.9464. Test: 0.9556, Loss: 0.0063\n",
      "Época 476: Train: 0.9994, Validation: 0.9509. Test: 0.9511, Loss: 0.0052\n",
      "Época 477: Train: 0.9994, Validation: 0.9554. Test: 0.9467, Loss: 0.0051\n",
      "Época 478: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0063\n",
      "Época 479: Train: 0.9994, Validation: 0.9554. Test: 0.9422, Loss: 0.0048\n",
      "Época 480: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0052\n",
      "Época 481: Train: 0.9994, Validation: 0.9509. Test: 0.9422, Loss: 0.0051\n",
      "Época 482: Train: 0.9994, Validation: 0.9598. Test: 0.9378, Loss: 0.0046\n",
      "Época 483: Train: 0.9994, Validation: 0.9598. Test: 0.9467, Loss: 0.0050\n",
      "Época 484: Train: 0.9994, Validation: 0.9554. Test: 0.9378, Loss: 0.0045\n",
      "Época 485: Train: 0.9994, Validation: 0.9554. Test: 0.9422, Loss: 0.0051\n",
      "Época 486: Train: 0.9989, Validation: 0.9464. Test: 0.9422, Loss: 0.0043\n",
      "Época 487: Train: 0.9994, Validation: 0.9420. Test: 0.9333, Loss: 0.0054\n",
      "Época 488: Train: 0.9933, Validation: 0.9554. Test: 0.9511, Loss: 0.0677\n",
      "Época 489: Train: 0.9911, Validation: 0.9420. Test: 0.9422, Loss: 0.0445\n",
      "Época 490: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0205\n",
      "Época 491: Train: 0.9994, Validation: 0.9598. Test: 0.9467, Loss: 0.0080\n",
      "Época 492: Train: 0.9994, Validation: 0.9509. Test: 0.9556, Loss: 0.0055\n",
      "Época 493: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0049\n",
      "Época 494: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0051\n",
      "Época 495: Train: 0.9994, Validation: 0.9554. Test: 0.9422, Loss: 0.0047\n",
      "Época 496: Train: 0.9994, Validation: 0.9554. Test: 0.9556, Loss: 0.0042\n",
      "Época 497: Train: 0.9994, Validation: 0.9509. Test: 0.9467, Loss: 0.0039\n",
      "Época 498: Train: 0.9994, Validation: 0.9554. Test: 0.9511, Loss: 0.0044\n",
      "Época 499: Train: 0.9989, Validation: 0.9554. Test: 0.9467, Loss: 0.0040\n",
      "Época 500: Train: 0.9989, Validation: 0.9554. Test: 0.9467, Loss: 0.0050\n"
     ]
    }
   ],
   "source": [
    "# Execução do treino\n",
    "train(data['train'], data['val'], data['test'], \n",
    "            args, num_node_features, num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
